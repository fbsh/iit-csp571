{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "42c0e674-9592-45c8-9385-b5023dffe375",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install xgboost\n",
    "# %pip install lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d8098e24",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-19T10:05:19.801244Z",
     "start_time": "2022-04-19T10:05:16.298553Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from xgboost import XGBClassifier\n",
    "import xgboost as xgb\n",
    "from lightgbm import LGBMClassifier\n",
    "import lightgbm as lgb\n",
    "from sklearn.ensemble import RandomForestClassifier,AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score,roc_auc_score,f1_score,recall_score,precision_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bd4084f5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-19T10:05:40.803114Z",
     "start_time": "2022-04-19T10:05:19.802164Z"
    }
   },
   "outputs": [],
   "source": [
    "data_root = '../data/'\n",
    "train_identity = pd.read_csv(f'{data_root}train_identity.csv')\n",
    "train_transaction = pd.read_csv(f'{data_root}train_transaction.csv')\n",
    "df = pd.merge(train_transaction, train_identity, on='TransactionID', how='left')\n",
    "del train_identity,train_transaction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "793a1065",
   "metadata": {},
   "source": [
    "# Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "371a5251",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-19T10:05:41.843332Z",
     "start_time": "2022-04-19T10:05:40.805011Z"
    }
   },
   "outputs": [],
   "source": [
    "#Delete columns with excessive proportion of nan values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "83f09c7a-7beb-4917-938d-703dcfdbc455",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "del dist2 nan rate: 0.9362837403054831\n",
      "del D7 nan rate: 0.9340992989467267\n",
      "del id_07 nan rate: 0.9912707013919464\n",
      "del id_08 nan rate: 0.9912707013919464\n",
      "del id_18 nan rate: 0.9236072069631185\n",
      "del id_21 nan rate: 0.9912639279303688\n",
      "del id_22 nan rate: 0.9912469942764249\n",
      "del id_23 nan rate: 0.9912469942764249\n",
      "del id_24 nan rate: 0.9919615944728554\n",
      "del id_25 nan rate: 0.9913096487960172\n",
      "del id_26 nan rate: 0.9912571544687913\n",
      "del id_27 nan rate: 0.9912469942764249\n"
     ]
    }
   ],
   "source": [
    "num_sample = len(df)\n",
    "threshold = 0.9\n",
    "for col in df.columns:\n",
    "    if (num_sample - df[col].count())/num_sample > threshold:\n",
    "        print(f'del {col} nan rate: {(num_sample - df[col].count())/num_sample}')\n",
    "        del df[col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c171ae48",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-19T10:05:44.999889Z",
     "start_time": "2022-04-19T10:05:41.844233Z"
    }
   },
   "outputs": [],
   "source": [
    "#nan value filling, 0 filling is used here.\n",
    "df = df.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "779b9372",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-19T10:05:47.968886Z",
     "start_time": "2022-04-19T10:05:45.000796Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 29/29 [00:02<00:00, 13.31it/s]\n"
     ]
    }
   ],
   "source": [
    "#Find and encode the features of discrete types.\n",
    "cate_cols = ['ProductCD', 'card4', 'card6', 'P_emaildomain', 'R_emaildomain', 'M1', 'M2', 'M3', 'M4', 'M5', 'M6', 'M7', 'M8', 'M9', 'id_12', 'id_15', 'id_16', 'id_28', 'id_29', 'id_30', 'id_31', 'id_33', 'id_34', 'id_35', 'id_36', 'id_37', 'id_38', 'DeviceType', 'DeviceInfo']\n",
    "for f in tqdm(cate_cols):\n",
    "    map_dict = dict(zip(df[f].unique(), range(df[f].nunique())))\n",
    "    df[f + '_count'] = df[f].map(df[f].value_counts())\n",
    "    df[f] = df[f].map(map_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a71f8098",
   "metadata": {},
   "source": [
    "# Slice data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "47a634c7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-19T10:05:51.106477Z",
     "start_time": "2022-04-19T10:05:47.971855Z"
    }
   },
   "outputs": [],
   "source": [
    "df = df.sample(frac=1).reset_index(drop=True) #Disrupt the order of data sets\n",
    "train_num = int(0.8*len(df)) \n",
    "valid_num = int(0.1*len(df))\n",
    "\n",
    "train_df = df[:train_num].reset_index(drop=True)\n",
    "valid_df = df[train_num:train_num+valid_num].reset_index(drop=True)\n",
    "test_df = df[train_num+valid_num:].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23361497",
   "metadata": {},
   "source": [
    "# Training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "18759e12",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-19T10:05:51.121434Z",
     "start_time": "2022-04-19T10:05:51.107471Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.50      0.50         4\n",
      "           1       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.33         6\n",
      "   macro avg       0.25      0.25      0.25         6\n",
      "weighted avg       0.33      0.33      0.33         6\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "y_true = [0,1,0,0,0,1]\n",
    "y_pred = [0,0,0,1,1,0]\n",
    "s=classification_report(y_true, y_pred)\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c90132aa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-19T10:05:51.137391Z",
     "start_time": "2022-04-19T10:05:51.123429Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_xgb(train_df, valid_df, test_df):\n",
    "    \n",
    "    label_col = 'isFraud'\n",
    "    drop_fea = ['isFraud']\n",
    "    feature = [x for x in train_df.columns if x not in drop_fea]\n",
    "\n",
    "    params = {\n",
    "        'booster': 'gbtree',\n",
    "        'objective': 'binary:logistic',\n",
    "        'eval_metric': 'auc',\n",
    "        'gamma': 0.1,\n",
    "        'max_depth': 6,\n",
    "        'alpha': 0,\n",
    "        'lambda': 0,\n",
    "        'subsample': 0.7,\n",
    "        'colsample_bytree': 0.5,\n",
    "        'min_child_weight': 3,\n",
    "        'silent': 0,\n",
    "        'eta': 0.03,\n",
    "        'nthread': -1,\n",
    "        'seed': 2019,\n",
    "    }\n",
    "\n",
    "    trn_data = xgb.DMatrix(train_df[feature], label=train_df[label_col])\n",
    "    val_data = xgb.DMatrix(valid_df[feature], label=valid_df[label_col])\n",
    "\n",
    "    watchlist = [(trn_data, 'train'), (val_data, 'valid')]\n",
    "    clf = xgb.train(params, trn_data, 1000, watchlist, verbose_eval=50, early_stopping_rounds=100)\n",
    "\n",
    "    ##Prediction\n",
    "    \n",
    "    y_pre = clf.predict(xgb.DMatrix(train_df[feature]), ntree_limit=clf.best_ntree_limit)\n",
    "    train_acc = accuracy_score(train_df[label_col],y_pre>0.5)\n",
    "    train_f1 = f1_score(train_df[label_col],y_pre>0.5)\n",
    "    train_recall = recall_score(train_df[label_col],y_pre>0.5)\n",
    "    train_precision = precision_score(train_df[label_col],y_pre>0.5)\n",
    "    \n",
    "    y_pre = clf.predict(xgb.DMatrix(valid_df[feature]), ntree_limit=clf.best_ntree_limit)\n",
    "    valid_acc = accuracy_score(valid_df[label_col],y_pre>0.5)\n",
    "    valid_f1 = f1_score(valid_df[label_col],y_pre>0.5)\n",
    "    valid_recall = recall_score(valid_df[label_col],y_pre>0.5)\n",
    "    valid_precision = precision_score(valid_df[label_col],y_pre>0.5)\n",
    "    \n",
    "    y_pre = clf.predict(xgb.DMatrix(test_df[feature]), ntree_limit=clf.best_ntree_limit)\n",
    "    test_acc = accuracy_score(test_df[label_col],y_pre>0.5)\n",
    "    test_f1 = f1_score(test_df[label_col],y_pre>0.5)\n",
    "    test_recall = recall_score(test_df[label_col],y_pre>0.5)\n",
    "    test_precision = precision_score(test_df[label_col],y_pre>0.5)\n",
    "    \n",
    "    return [train_acc, valid_acc, test_acc, train_f1, valid_f1, test_f1, train_recall, valid_recall, test_recall, train_precision, valid_precision, test_precision]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5c312b52",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-19T10:05:51.152397Z",
     "start_time": "2022-04-19T10:05:51.138390Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_lgb(train_df, valid_df, test_df):\n",
    "    label_col = 'isFraud'\n",
    "    drop_fea = ['isFraud']\n",
    "    feature = [x for x in train_df.columns if x not in drop_fea]\n",
    "    \n",
    "    params = {'num_leaves': 60,\n",
    "          'min_data_in_leaf': 30,\n",
    "          'objective': 'binary', \n",
    "          'max_depth': -1,\n",
    "          'learning_rate': 0.06,\n",
    "          \"min_sum_hessian_in_leaf\": 6,\n",
    "          \"boosting\": \"gbdt\",\n",
    "          \"feature_fraction\": 0.9,  \n",
    "          \"bagging_freq\": 1,\n",
    "          \"bagging_fraction\": 0.8,\n",
    "          \"bagging_seed\": 11,\n",
    "          \"lambda_l1\": 0.1,             \n",
    "          \"verbosity\": -1,\n",
    "          \"nthread\": -1,                \n",
    "          'metric': {'binary_logloss', 'auc'},  \n",
    "          \"random_state\": 2019, \n",
    "          }\n",
    "    \n",
    "    trn_data = lgb.Dataset(train_df[feature], label=train_df[label_col])\n",
    "    val_data = lgb.Dataset(valid_df[feature], label=valid_df[label_col])\n",
    "\n",
    "\n",
    "    clf = lgb.train(params,\n",
    "                    trn_data,\n",
    "                    1000,\n",
    "                    valid_sets=[trn_data, val_data],\n",
    "                    verbose_eval=20,\n",
    "                    early_stopping_rounds=60)\n",
    "    \n",
    "    ##Prediction\n",
    "      \n",
    "    y_pre = clf.predict(train_df[feature], num_iteration=clf.best_iteration)\n",
    "    train_acc = accuracy_score(train_df[label_col],y_pre>0.5)\n",
    "    train_f1 = f1_score(train_df[label_col],y_pre>0.5)\n",
    "    train_recall = recall_score(train_df[label_col],y_pre>0.5)\n",
    "    train_precision = precision_score(train_df[label_col],y_pre>0.5)\n",
    "    \n",
    "    y_pre = clf.predict(valid_df[feature], num_iteration=clf.best_iteration)\n",
    "    valid_acc = accuracy_score(valid_df[label_col],y_pre>0.5)\n",
    "    valid_f1 = f1_score(valid_df[label_col],y_pre>0.5)\n",
    "    valid_recall = recall_score(valid_df[label_col],y_pre>0.5)\n",
    "    valid_precision = precision_score(valid_df[label_col],y_pre>0.5)\n",
    "    \n",
    "    y_pre = clf.predict(test_df[feature], num_iteration=clf.best_iteration)\n",
    "    test_acc = accuracy_score(test_df[label_col],y_pre>0.5)\n",
    "    test_f1 = f1_score(test_df[label_col],y_pre>0.5)\n",
    "    test_recall = recall_score(test_df[label_col],y_pre>0.5)\n",
    "    test_precision = precision_score(test_df[label_col],y_pre>0.5)\n",
    "    \n",
    "    return [train_acc, valid_acc, test_acc, train_f1, valid_f1, test_f1, train_recall, valid_recall, test_recall, train_precision, valid_precision, test_precision]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "89cbe5a4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-19T10:05:51.168314Z",
     "start_time": "2022-04-19T10:05:51.153377Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_rf(train_df,valid_df,test_df):\n",
    "    label_col = 'isFraud'\n",
    "    drop_fea = ['isFraud']\n",
    "    feature = [x for x in train_df.columns if x not in drop_fea]\n",
    "\n",
    "    clf = RandomForestClassifier(n_estimators=100,max_depth=6,random_state=11,verbose=1,n_jobs=-1)\n",
    "\n",
    "    clf.fit(train_df[feature],train_df[label_col])\n",
    "    \n",
    "    ##Prediction\n",
    "    \n",
    "    y_pre = clf.predict(train_df[feature])\n",
    "    train_acc = accuracy_score(train_df[label_col],y_pre)\n",
    "    train_f1 = f1_score(train_df[label_col],y_pre)\n",
    "    train_recall = recall_score(train_df[label_col],y_pre)\n",
    "    train_precision = precision_score(train_df[label_col],y_pre)\n",
    "    \n",
    "    y_pre = clf.predict(valid_df[feature])\n",
    "    valid_acc = accuracy_score(valid_df[label_col],y_pre)\n",
    "    valid_f1 = f1_score(valid_df[label_col],y_pre)\n",
    "    valid_recall = recall_score(valid_df[label_col],y_pre)\n",
    "    valid_precision = precision_score(valid_df[label_col],y_pre)\n",
    "    \n",
    "    y_pre = clf.predict(test_df[feature])\n",
    "    test_acc = accuracy_score(test_df[label_col],y_pre)\n",
    "    test_f1 = f1_score(test_df[label_col],y_pre)\n",
    "    test_recall = recall_score(test_df[label_col],y_pre)\n",
    "    test_precision = precision_score(test_df[label_col],y_pre)\n",
    "    \n",
    "    return [train_acc, valid_acc, test_acc, train_f1, valid_f1, test_f1, train_recall, valid_recall, test_recall, train_precision, valid_precision, test_precision]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f6176d9e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-19T10:05:51.184270Z",
     "start_time": "2022-04-19T10:05:51.169306Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_nn(train_df,valid_df,test_df):\n",
    "\n",
    "    label_col = 'isFraud'\n",
    "    drop_fea = ['isFraud']\n",
    "    feature = [x for x in train_df.columns if x not in drop_fea]\n",
    "\n",
    "    clf = MLPClassifier(solver = 'adam',verbose=1, activation = 'logistic', max_iter = 100,learning_rate_init=0.01,\n",
    "                        hidden_layer_sizes = (128,32),random_state = 4399, early_stopping=True)\n",
    "\n",
    "    scaler = preprocessing.StandardScaler().fit(train_df[feature])\n",
    "    train_df[feature] = scaler.transform(train_df[feature])\n",
    "    valid_df[feature] = scaler.transform(valid_df[feature])\n",
    "    test_df[feature] = scaler.transform(test_df[feature])\n",
    "\n",
    "    clf.fit(train_df[feature],train_df[label_col])\n",
    "\n",
    "    ##Prediction\n",
    "\n",
    "    y_pre = clf.predict(train_df[feature])\n",
    "    train_acc = accuracy_score(train_df[label_col],y_pre)\n",
    "    train_f1 = f1_score(train_df[label_col],y_pre)\n",
    "    train_recall = recall_score(train_df[label_col],y_pre)\n",
    "    train_precision = precision_score(train_df[label_col],y_pre)\n",
    "\n",
    "    y_pre = clf.predict(valid_df[feature])\n",
    "    valid_acc = accuracy_score(valid_df[label_col],y_pre)\n",
    "    valid_f1 = f1_score(valid_df[label_col],y_pre)\n",
    "    valid_recall = recall_score(valid_df[label_col],y_pre)\n",
    "    valid_precision = precision_score(valid_df[label_col],y_pre)\n",
    "\n",
    "    y_pre = clf.predict(test_df[feature])\n",
    "    test_acc = accuracy_score(test_df[label_col],y_pre)\n",
    "    test_f1 = f1_score(test_df[label_col],y_pre)\n",
    "    test_recall = recall_score(test_df[label_col],y_pre)\n",
    "    test_precision = precision_score(test_df[label_col],y_pre)\n",
    "\n",
    "\n",
    "    \n",
    "    return [train_acc, valid_acc, test_acc, train_f1, valid_f1, test_f1, train_recall, valid_recall, test_recall, train_precision, valid_precision, test_precision]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fe808395",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-19T10:05:51.200223Z",
     "start_time": "2022-04-19T10:05:51.185264Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_all_model(train_df, valid_df, test_df):\n",
    "    print('[INFO] Train LGB')\n",
    "    lgb_acc = train_lgb(train_df, valid_df, test_df)\n",
    "    print('[INFO] Train RF')\n",
    "    rf_acc = train_rf(train_df, valid_df, test_df)\n",
    "    print('[INFO] Train NN')\n",
    "    nn_acc = train_nn(train_df, valid_df, test_df)\n",
    "    print('[INFO] Train XGB')\n",
    "    xgb_acc = train_xgb(train_df, valid_df, test_df)\n",
    "    \n",
    "    print('*'*100)\n",
    "    print('LGB: Train acc:{:.4f} Valid acc:{:.4f} Test acc:{:.4f}'.format(lgb_acc[0],lgb_acc[1],lgb_acc[2]))\n",
    "    print('LGB: Train f1:{:.4f} Valid f1:{:.4f} Test f1:{:.4f}'.format(lgb_acc[3],lgb_acc[4],lgb_acc[5]))\n",
    "    print('LGB: Train recall:{:.4f} Valid recall:{:.4f} Test recall:{:.4f}'.format(lgb_acc[6],lgb_acc[7],lgb_acc[8]))\n",
    "    print('LGB: Train precision:{:.4f} Valid precision:{:.4f} Test precision:{:.4f}'.format(lgb_acc[9],lgb_acc[10],lgb_acc[11]))\n",
    "    print('*'*100)\n",
    "    \n",
    "    print('*'*100)\n",
    "    print('XGB: Train acc:{:.4f} Valid acc:{:.4f} Test acc:{:.4f}'.format(xgb_acc[0],xgb_acc[1],xgb_acc[2]))\n",
    "    print('XGB: Train f1:{:.4f} Valid f1:{:.4f} Test f1:{:.4f}'.format(xgb_acc[3],xgb_acc[4],xgb_acc[5]))\n",
    "    print('XGB: Train recall:{:.4f} Valid recall:{:.4f} Test recall:{:.4f}'.format(xgb_acc[6],xgb_acc[7],xgb_acc[8]))\n",
    "    print('XGB: Train precision:{:.4f} Valid precision:{:.4f} Test precision:{:.4f}'.format(xgb_acc[9],xgb_acc[10],xgb_acc[11]))\n",
    "    print('*'*100)\n",
    "    \n",
    "    print('*'*100)\n",
    "    print('RF: Train acc:{:.4f} Valid acc:{:.4f} Test acc:{:.4f}'.format(rf_acc[0],rf_acc[1],rf_acc[2]))\n",
    "    print('RF: Train f1:{:.4f} Valid f1:{:.4f} Test f1:{:.4f}'.format(rf_acc[3],rf_acc[4],rf_acc[5]))\n",
    "    print('RF: Train recall:{:.4f} Valid recall:{:.4f} Test recall:{:.4f}'.format(rf_acc[6],rf_acc[7],rf_acc[8]))\n",
    "    print('RF: Train precision:{:.4f} Valid precision:{:.4f} Test precision:{:.4f}'.format(rf_acc[9],rf_acc[10],rf_acc[11]))\n",
    "    print('*'*100)\n",
    "    \n",
    "    print('*'*100)\n",
    "    print('NN: Train acc:{:.4f} Valid acc:{:.4f} Test acc:{:.4f}'.format(nn_acc[0],nn_acc[1],nn_acc[2]))\n",
    "    print('NN: Train f1:{:.4f} Valid f1:{:.4f} Test f1:{:.4f}'.format(nn_acc[3],nn_acc[4],nn_acc[5]))\n",
    "    print('NN: Train recall:{:.4f} Valid recall:{:.4f} Test recall:{:.4f}'.format(nn_acc[6],nn_acc[7],nn_acc[8]))\n",
    "    print('NN: Train precision:{:.4f} Valid precision:{:.4f} Test precision:{:.4f}'.format(nn_acc[9],nn_acc[10],nn_acc[11]))\n",
    "    print('*'*100)\n",
    "    \n",
    "    return lgb_acc,xgb_acc,rf_acc,nn_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5b21644c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-19T10:25:28.797993Z",
     "start_time": "2022-04-19T10:05:51.201221Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Train LGB\n",
      "Training until validation scores don't improve for 60 rounds\n",
      "[20]\ttraining's binary_logloss: 0.0958519\ttraining's auc: 0.892941\tvalid_1's binary_logloss: 0.0979825\tvalid_1's auc: 0.885291\n",
      "[40]\ttraining's binary_logloss: 0.0841684\ttraining's auc: 0.91331\tvalid_1's binary_logloss: 0.0878075\tvalid_1's auc: 0.901737\n",
      "[60]\ttraining's binary_logloss: 0.0776605\ttraining's auc: 0.926343\tvalid_1's binary_logloss: 0.0822016\tvalid_1's auc: 0.913117\n",
      "[80]\ttraining's binary_logloss: 0.0731154\ttraining's auc: 0.935238\tvalid_1's binary_logloss: 0.078638\tvalid_1's auc: 0.919881\n",
      "[100]\ttraining's binary_logloss: 0.0694938\ttraining's auc: 0.942049\tvalid_1's binary_logloss: 0.076128\tvalid_1's auc: 0.924671\n",
      "[120]\ttraining's binary_logloss: 0.0665733\ttraining's auc: 0.94745\tvalid_1's binary_logloss: 0.0739167\tvalid_1's auc: 0.929501\n",
      "[140]\ttraining's binary_logloss: 0.0641588\ttraining's auc: 0.951405\tvalid_1's binary_logloss: 0.072197\tvalid_1's auc: 0.932484\n",
      "[160]\ttraining's binary_logloss: 0.0620135\ttraining's auc: 0.955093\tvalid_1's binary_logloss: 0.0705533\tvalid_1's auc: 0.935471\n",
      "[180]\ttraining's binary_logloss: 0.0600227\ttraining's auc: 0.958502\tvalid_1's binary_logloss: 0.0691105\tvalid_1's auc: 0.938602\n",
      "[200]\ttraining's binary_logloss: 0.0582585\ttraining's auc: 0.961113\tvalid_1's binary_logloss: 0.0679029\tvalid_1's auc: 0.940574\n",
      "[220]\ttraining's binary_logloss: 0.0566498\ttraining's auc: 0.963488\tvalid_1's binary_logloss: 0.0668351\tvalid_1's auc: 0.942242\n",
      "[240]\ttraining's binary_logloss: 0.0552113\ttraining's auc: 0.96545\tvalid_1's binary_logloss: 0.0658828\tvalid_1's auc: 0.94383\n",
      "[260]\ttraining's binary_logloss: 0.0538036\ttraining's auc: 0.967514\tvalid_1's binary_logloss: 0.0649465\tvalid_1's auc: 0.94563\n",
      "[280]\ttraining's binary_logloss: 0.0525441\ttraining's auc: 0.9692\tvalid_1's binary_logloss: 0.064105\tvalid_1's auc: 0.946883\n",
      "[300]\ttraining's binary_logloss: 0.0513569\ttraining's auc: 0.970818\tvalid_1's binary_logloss: 0.0633289\tvalid_1's auc: 0.947811\n",
      "[320]\ttraining's binary_logloss: 0.0502235\ttraining's auc: 0.972594\tvalid_1's binary_logloss: 0.0625901\tvalid_1's auc: 0.949244\n",
      "[340]\ttraining's binary_logloss: 0.049123\ttraining's auc: 0.974139\tvalid_1's binary_logloss: 0.0619001\tvalid_1's auc: 0.950267\n",
      "[360]\ttraining's binary_logloss: 0.0480928\ttraining's auc: 0.975481\tvalid_1's binary_logloss: 0.0612572\tvalid_1's auc: 0.951341\n",
      "[380]\ttraining's binary_logloss: 0.0468977\ttraining's auc: 0.977153\tvalid_1's binary_logloss: 0.0604849\tvalid_1's auc: 0.952668\n",
      "[400]\ttraining's binary_logloss: 0.0458568\ttraining's auc: 0.978397\tvalid_1's binary_logloss: 0.0598138\tvalid_1's auc: 0.953603\n",
      "[420]\ttraining's binary_logloss: 0.0448864\ttraining's auc: 0.979569\tvalid_1's binary_logloss: 0.0591748\tvalid_1's auc: 0.954519\n",
      "[440]\ttraining's binary_logloss: 0.0440371\ttraining's auc: 0.980556\tvalid_1's binary_logloss: 0.0587311\tvalid_1's auc: 0.955117\n",
      "[460]\ttraining's binary_logloss: 0.0431299\ttraining's auc: 0.98157\tvalid_1's binary_logloss: 0.0582438\tvalid_1's auc: 0.955889\n",
      "[480]\ttraining's binary_logloss: 0.0422812\ttraining's auc: 0.982555\tvalid_1's binary_logloss: 0.0577539\tvalid_1's auc: 0.956646\n",
      "[500]\ttraining's binary_logloss: 0.0413799\ttraining's auc: 0.983613\tvalid_1's binary_logloss: 0.0572562\tvalid_1's auc: 0.957393\n",
      "[520]\ttraining's binary_logloss: 0.0405433\ttraining's auc: 0.984467\tvalid_1's binary_logloss: 0.0567766\tvalid_1's auc: 0.958222\n",
      "[540]\ttraining's binary_logloss: 0.0397393\ttraining's auc: 0.985298\tvalid_1's binary_logloss: 0.0563\tvalid_1's auc: 0.958963\n",
      "[560]\ttraining's binary_logloss: 0.0389479\ttraining's auc: 0.986119\tvalid_1's binary_logloss: 0.0558347\tvalid_1's auc: 0.959589\n",
      "[580]\ttraining's binary_logloss: 0.0382971\ttraining's auc: 0.986648\tvalid_1's binary_logloss: 0.0554745\tvalid_1's auc: 0.959969\n",
      "[600]\ttraining's binary_logloss: 0.0376329\ttraining's auc: 0.987272\tvalid_1's binary_logloss: 0.0550955\tvalid_1's auc: 0.960635\n",
      "[620]\ttraining's binary_logloss: 0.0368789\ttraining's auc: 0.987982\tvalid_1's binary_logloss: 0.0547107\tvalid_1's auc: 0.96102\n",
      "[640]\ttraining's binary_logloss: 0.036191\ttraining's auc: 0.988611\tvalid_1's binary_logloss: 0.0543388\tvalid_1's auc: 0.961588\n",
      "[660]\ttraining's binary_logloss: 0.0354942\ttraining's auc: 0.989254\tvalid_1's binary_logloss: 0.0539402\tvalid_1's auc: 0.962203\n",
      "[680]\ttraining's binary_logloss: 0.034879\ttraining's auc: 0.989762\tvalid_1's binary_logloss: 0.0536485\tvalid_1's auc: 0.962499\n",
      "[700]\ttraining's binary_logloss: 0.0342566\ttraining's auc: 0.990302\tvalid_1's binary_logloss: 0.053345\tvalid_1's auc: 0.963014\n",
      "[720]\ttraining's binary_logloss: 0.0337189\ttraining's auc: 0.990703\tvalid_1's binary_logloss: 0.0530574\tvalid_1's auc: 0.963311\n",
      "[740]\ttraining's binary_logloss: 0.033123\ttraining's auc: 0.991141\tvalid_1's binary_logloss: 0.0527021\tvalid_1's auc: 0.963685\n",
      "[760]\ttraining's binary_logloss: 0.0325091\ttraining's auc: 0.991598\tvalid_1's binary_logloss: 0.0524022\tvalid_1's auc: 0.964095\n",
      "[780]\ttraining's binary_logloss: 0.0319204\ttraining's auc: 0.991981\tvalid_1's binary_logloss: 0.0520317\tvalid_1's auc: 0.964526\n",
      "[800]\ttraining's binary_logloss: 0.0313953\ttraining's auc: 0.992353\tvalid_1's binary_logloss: 0.0518099\tvalid_1's auc: 0.964791\n",
      "[820]\ttraining's binary_logloss: 0.0309287\ttraining's auc: 0.99263\tvalid_1's binary_logloss: 0.0515791\tvalid_1's auc: 0.965038\n",
      "[840]\ttraining's binary_logloss: 0.0304103\ttraining's auc: 0.992962\tvalid_1's binary_logloss: 0.0513827\tvalid_1's auc: 0.965355\n",
      "[860]\ttraining's binary_logloss: 0.0299247\ttraining's auc: 0.993249\tvalid_1's binary_logloss: 0.0511481\tvalid_1's auc: 0.965648\n",
      "[880]\ttraining's binary_logloss: 0.0294302\ttraining's auc: 0.993538\tvalid_1's binary_logloss: 0.0508861\tvalid_1's auc: 0.965881\n",
      "[900]\ttraining's binary_logloss: 0.0289363\ttraining's auc: 0.993832\tvalid_1's binary_logloss: 0.0506198\tvalid_1's auc: 0.966265\n",
      "[920]\ttraining's binary_logloss: 0.0284909\ttraining's auc: 0.994119\tvalid_1's binary_logloss: 0.0504374\tvalid_1's auc: 0.966516\n",
      "[940]\ttraining's binary_logloss: 0.0280065\ttraining's auc: 0.994396\tvalid_1's binary_logloss: 0.0502115\tvalid_1's auc: 0.966874\n",
      "[960]\ttraining's binary_logloss: 0.0275766\ttraining's auc: 0.994636\tvalid_1's binary_logloss: 0.0500103\tvalid_1's auc: 0.967217\n",
      "[980]\ttraining's binary_logloss: 0.0271552\ttraining's auc: 0.994856\tvalid_1's binary_logloss: 0.0498042\tvalid_1's auc: 0.967532\n",
      "[1000]\ttraining's binary_logloss: 0.0267291\ttraining's auc: 0.995101\tvalid_1's binary_logloss: 0.0495801\tvalid_1's auc: 0.967871\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\ttraining's binary_logloss: 0.0267291\ttraining's auc: 0.995101\tvalid_1's binary_logloss: 0.0495801\tvalid_1's auc: 0.967871\n",
      "[INFO] Train RF\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    6.6s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:   19.6s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=12)]: Done 100 out of 100 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Train NN\n",
      "Iteration 1, loss = 0.11207488\n",
      "Validation score: 0.971340\n",
      "Iteration 2, loss = 0.10737790\n",
      "Validation score: 0.971171\n",
      "Iteration 3, loss = 0.10634000\n",
      "Validation score: 0.971531\n",
      "Iteration 4, loss = 0.10627922\n",
      "Validation score: 0.971361\n",
      "Iteration 5, loss = 0.10565607\n",
      "Validation score: 0.972039\n",
      "Iteration 6, loss = 0.10547238\n",
      "Validation score: 0.973436\n",
      "Iteration 7, loss = 0.10485044\n",
      "Validation score: 0.973161\n",
      "Iteration 8, loss = 0.10483017\n",
      "Validation score: 0.973118\n",
      "Iteration 9, loss = 0.10457459\n",
      "Validation score: 0.972631\n",
      "Iteration 10, loss = 0.10427984\n",
      "Validation score: 0.973034\n",
      "Iteration 11, loss = 0.10445549\n",
      "Validation score: 0.971488\n",
      "Iteration 12, loss = 0.10428688\n",
      "Validation score: 0.973182\n",
      "Iteration 13, loss = 0.10380164\n",
      "Validation score: 0.973690\n",
      "Iteration 14, loss = 0.10324046\n",
      "Validation score: 0.972991\n",
      "Iteration 15, loss = 0.10302937\n",
      "Validation score: 0.973563\n",
      "Iteration 16, loss = 0.10353329\n",
      "Validation score: 0.973563\n",
      "Iteration 17, loss = 0.10337950\n",
      "Validation score: 0.973753\n",
      "Iteration 18, loss = 0.10341513\n",
      "Validation score: 0.973436\n",
      "Iteration 19, loss = 0.10238875\n",
      "Validation score: 0.973796\n",
      "Iteration 20, loss = 0.10308236\n",
      "Validation score: 0.972420\n",
      "Iteration 21, loss = 0.10262860\n",
      "Validation score: 0.973245\n",
      "Iteration 22, loss = 0.10216850\n",
      "Validation score: 0.973669\n",
      "Iteration 23, loss = 0.10289870\n",
      "Validation score: 0.973520\n",
      "Iteration 24, loss = 0.10203200\n",
      "Validation score: 0.972695\n",
      "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "[INFO] Train XGB\n",
      "[18:11:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-auc:0.76869\tvalid-auc:0.76284\n",
      "[50]\ttrain-auc:0.86504\tvalid-auc:0.86121\n",
      "[100]\ttrain-auc:0.88835\tvalid-auc:0.88171\n",
      "[150]\ttrain-auc:0.90307\tvalid-auc:0.89259\n",
      "[200]\ttrain-auc:0.91428\tvalid-auc:0.90067\n",
      "[250]\ttrain-auc:0.92185\tvalid-auc:0.90728\n",
      "[300]\ttrain-auc:0.92718\tvalid-auc:0.91239\n",
      "[350]\ttrain-auc:0.93109\tvalid-auc:0.91588\n",
      "[400]\ttrain-auc:0.93432\tvalid-auc:0.91865\n",
      "[450]\ttrain-auc:0.93732\tvalid-auc:0.92139\n",
      "[500]\ttrain-auc:0.94010\tvalid-auc:0.92390\n",
      "[550]\ttrain-auc:0.94242\tvalid-auc:0.92604\n",
      "[600]\ttrain-auc:0.94471\tvalid-auc:0.92799\n",
      "[650]\ttrain-auc:0.94674\tvalid-auc:0.92967\n",
      "[700]\ttrain-auc:0.94873\tvalid-auc:0.93151\n",
      "[750]\ttrain-auc:0.95022\tvalid-auc:0.93273\n",
      "[800]\ttrain-auc:0.95180\tvalid-auc:0.93437\n",
      "[850]\ttrain-auc:0.95375\tvalid-auc:0.93609\n",
      "[900]\ttrain-auc:0.95503\tvalid-auc:0.93718\n",
      "[950]\ttrain-auc:0.95606\tvalid-auc:0.93800\n",
      "[999]\ttrain-auc:0.95717\tvalid-auc:0.93890\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wk\\Anaconda\\envs\\torch\\lib\\site-packages\\xgboost\\core.py:104: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "  UserWarning\n",
      "C:\\Users\\wk\\Anaconda\\envs\\torch\\lib\\site-packages\\xgboost\\core.py:104: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "  UserWarning\n",
      "C:\\Users\\wk\\Anaconda\\envs\\torch\\lib\\site-packages\\xgboost\\core.py:104: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "  UserWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************************************************************************************\n",
      "LGB: Train acc:0.9927 Valid acc:0.9860 Test acc:0.9862\n",
      "LGB: Train f1:0.8841 Valid f1:0.7575 Test f1:0.7615\n",
      "LGB: Train recall:0.7945 Valid recall:0.6252 Test recall:0.6332\n",
      "LGB: Train precision:0.9964 Valid precision:0.9606 Test precision:0.9551\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "XGB: Train acc:0.9829 Valid acc:0.9808 Test acc:0.9815\n",
      "XGB: Train f1:0.6856 Valid f1:0.6375 Test f1:0.6516\n",
      "XGB: Train recall:0.5321 Valid recall:0.4826 Test recall:0.4985\n",
      "XGB: Train precision:0.9633 Valid precision:0.9389 Test precision:0.9402\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "RF: Train acc:0.9714 Valid acc:0.9708 Test acc:0.9713\n",
      "RF: Train f1:0.3342 Valid f1:0.3131 Test f1:0.3239\n",
      "RF: Train recall:0.2048 Valid recall:0.1900 Test recall:0.1980\n",
      "RF: Train precision:0.9066 Valid precision:0.8891 Test precision:0.8884\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "NN: Train acc:0.9750 Valid acc:0.9736 Test acc:0.9748\n",
      "NN: Train f1:0.4960 Valid f1:0.4639 Test f1:0.4878\n",
      "NN: Train recall:0.3506 Valid recall:0.3264 Test recall:0.3463\n",
      "NN: Train precision:0.8475 Valid precision:0.8017 Test precision:0.8246\n",
      "****************************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "lgb_acc,xgb_acc,rf_acc,nn_acc = train_all_model(train_df, valid_df, test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e89872d8",
   "metadata": {},
   "source": [
    "# Comparing Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "181aa0bf",
   "metadata": {},
   "source": [
    "****************************************************************************************************\n",
    "LGB: Train acc:0.9927 Valid acc:0.9858 Test acc:0.9857\n",
    "LGB: Train f1:0.8834 Valid f1:0.7616 Test f1:0.7585\n",
    "LGB: Train recall:0.7937 Valid recall:0.6339 Test recall:0.6295\n",
    "LGB: Train precision:0.9958 Valid precision:0.9536 Test precision:0.9540\n",
    "****************************************************************************************************\n",
    "****************************************************************************************************\n",
    "XGB: Train acc:0.9831 Valid acc:0.9804 Test acc:0.9803\n",
    "XGB: Train f1:0.6871 Valid f1:0.6368 Test f1:0.6352\n",
    "XGB: Train recall:0.5335 Valid recall:0.4824 Test recall:0.4796\n",
    "XGB: Train precision:0.9649 Valid precision:0.9364 Test precision:0.9405\n",
    "****************************************************************************************************\n",
    "****************************************************************************************************\n",
    "RF: Train acc:0.9716 Valid acc:0.9706 Test acc:0.9710\n",
    "RF: Train f1:0.3361 Valid f1:0.3277 Test f1:0.3362\n",
    "RF: Train recall:0.2061 Valid recall:0.2009 Test recall:0.2059\n",
    "RF: Train precision:0.9101 Valid precision:0.8887 Test precision:0.9156\n",
    "****************************************************************************************************\n",
    "****************************************************************************************************\n",
    "NN: Train acc:0.9751 Valid acc:0.9735 Test acc:0.9744\n",
    "NN: Train f1:0.5149 Valid f1:0.4947 Test f1:0.5105\n",
    "NN: Train recall:0.3788 Valid recall:0.3632 Test recall:0.3738\n",
    "NN: Train precision:0.8036 Valid precision:0.7751 Test precision:0.8049\n",
    "****************************************************************************************************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f468fc6b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
